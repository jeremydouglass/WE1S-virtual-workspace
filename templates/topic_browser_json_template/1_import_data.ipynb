{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## INFO\n",
    "\n",
    "__author__    = 'Jeremy Douglass'\n",
    "__copyright__ = 'copyright 2017, The WE1S Project'\n",
    "__license__   = 'GPL'\n",
    "__version__   = '0.6'\n",
    "__email__     = 'jeremydouglass@gmail.com'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## IMPORT\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Choose a datafolder and file from \n",
    "\n",
    "jsondatadir = '/home/jovyan/work/write/data/'\n",
    "datafile_list = ['2017-01-humanities/team1_humanities_month.zip',\n",
    "                 '158208_koreaherald_humanities.zip',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## SETTINGS\n",
    "\n",
    "## project directory\n",
    "project_dir = %pwd\n",
    "print(project_dir)\n",
    "\n",
    "## import global project settings from config.py\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for datafile in datafile_list:\n",
    "    datapath = jsondatadir + datafile\n",
    "    !mkdir -p caches/json\n",
    "    !unzip -j -o -u \"{datapath}\" -d caches/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DEFINE METADATA STRINGCLEANER\n",
    "\n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "def string_cleaner(unistr):\n",
    "    \"\"\"Returns string in unaccented form, printable characters only.\"\"\"\n",
    "    unaccented = unidecode.unidecode(unistr)\n",
    "    printonly = ''.join(filter(lambda x:x in string.printable, unaccented))\n",
    "    return printonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CREATE METADATA FROM JSON FILES\n",
    "\n",
    "import json\n",
    "\n",
    "## Delete old metadata files\n",
    "!rm -fr {metadata_dir}\n",
    "!mkdir -p {metadata_dir}\n",
    "\n",
    "json_directory = 'caches/json/'\n",
    "\n",
    "## id, publication, pubdate, title, articlebody, author, docUrl, wordcount\n",
    "\n",
    "## idx       ->  id\n",
    "## pub       ->  publication\n",
    "## pub_date  ->  pubdate\n",
    "## title     ->  title\n",
    "## content   ->  articlebody\n",
    "\n",
    "##           ->  author\n",
    "##           ->  docUrl\n",
    "## length    ->  wordcount\n",
    "\n",
    "csv.field_size_limit(100000000)\n",
    "\n",
    "with open('caches/json-metadata.csv', 'w') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile, delimiter=',')\n",
    "    csvwriter.writerow(['id'] + ['publication'] + ['pubdate'] + ['title'] + ['articlebody'] + ['author'] + ['docUrl'] + ['wordcount'])\n",
    "    for idx, filename in enumerate(os.listdir(json_directory)):\n",
    "        if filename.endswith(\".json\"):\n",
    "            print(filename)\n",
    "            with open(os.path.join(json_directory, filename)) as f:\n",
    "                j = json.loads(f.read())\n",
    "                print(idx)\n",
    "                print(j['pub'])\n",
    "                csvwriter.writerow([idx] + [j['pub']] + [j['pub_date']] + [j['title']] + [string_cleaner(j['content'])])\n",
    "\n",
    "                metadata_csv_files = ['caches/json-metadata.csv']\n",
    "\n",
    "metadata_csv_files = ['caches/json-metadata.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Copy metadata file list\n",
    "metadata_out = project_dir + '/' + metadata_dir + '/'\n",
    "for f in metadata_csv_files:\n",
    "    shutil.copy(f, metadata_out)\n",
    "!ls -1 {metadata_out}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CHECK METADATA\n",
    "\n",
    "!echo CHECK METADATA\n",
    "!echo\n",
    "!echo {metadata_dir} :\n",
    "!echo\n",
    "!ls -1 {metadata_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## MERGE METADATA\n",
    "\n",
    "## Delete old merged metadata\n",
    "print(metadata_dir, ': \\n')\n",
    "\n",
    "!rm -f {metadata_file}\n",
    "\n",
    "with open(metadata_file, 'w') as fout:\n",
    "    # copy header from first file\n",
    "    headerfile = open(metadata_csv_files[0])\n",
    "    fout.write(headerfile.readline())\n",
    "    ## copy bodies\n",
    "    wout = csv.writer(fout)\n",
    "    for filename in metadata_csv_files:\n",
    "        print('Processing', filename)\n",
    "        with open(filename, 'r') as fin:\n",
    "            win = csv.reader(fin)\n",
    "            next(win) # skip header\n",
    "            wout.writerows(win)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CHECK MERGE\n",
    "\n",
    "!echo CHECK MERGE\n",
    "!echo\n",
    "!echo {metadata_file} :\n",
    "!echo\n",
    "!head -n 2 {metadata_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## COPY TEXT\n",
    "## Replaced by the metadata csv export\n",
    "# for file in glob.glob(text_file_directory+r'/*.txt'):\n",
    "#    shutil.copy(file, project_directory+'/text_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EXPORT ARTICLE BODIES TO TEXT FILES\n",
    "\n",
    "## Source CSV fields:\n",
    "## id, publication, pubdate, title, articlebody, author, docUrl, wordcount\n",
    "\n",
    "## Delete old text files\n",
    "!rm -fr {text_files_dir}\n",
    "!mkdir -p {text_files_dir}\n",
    "\n",
    "## Export\n",
    "with open(metadata_file, 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    ## skip header row\n",
    "    # next(reader, None)\n",
    "    for row in reader:\n",
    "        with open(project_dir+'/' + text_files_dir + '/'+ row['id'] + '_.txt', 'w') as outfile:\n",
    "            # writer = csv.DictWriter(outfile, fieldnames=outfieldnames)\n",
    "            outfile.write(row['articlebody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## CHECK TEXT FILES\n",
    "\n",
    "!echo CHECK TEXT FILES\n",
    "!echo\n",
    "!echo {text_files_dir} :\n",
    "!echo\n",
    "!ls -1 {text_files_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## NEXT\n",
    "## Generate a link to the next notebook in the workflow\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "browser_link_html = HTML('<p>The data is imported into ~/metadata/ and ~/text_files/.</p><h2><a href=\"2_clean_data.ipynb\" target=\"_blank\">Next: Clean Data.</h2>')\n",
    "display(browser_link_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

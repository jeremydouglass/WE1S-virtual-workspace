{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "Import metadata and generate data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SETTINGS\n",
    "\n",
    "## project directory\n",
    "project_dir    = %pwd\n",
    "print(project_dir)\n",
    "\n",
    "## import global project settings from config.py\n",
    "from settings import *\n",
    "\n",
    "print(metadata_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD\n",
    "\n",
    "## (single file)\n",
    "# metadata_csv_file   = '../../../read/washington_post/working_data/2000/humanities/aggregate_working_data/clean/washington_post-2000-h-master-clean.csv'\n",
    "# text_file_directory = '../../../read/washington_post/working_data/2000/humanities/individual_plain_text'\n",
    "\n",
    "## copy metadata (single file)\n",
    "# shutil.copy(metadata_csv_file,project_directory+'/metadata/metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORT METADATA\n",
    "\n",
    "## Delete old metadata files\n",
    "!rm -fr {metadata_dir}\n",
    "!mkdir -p {metadata_dir}\n",
    "\n",
    "## Copy metadata file list\n",
    "for f in metadata_csv_files:\n",
    "    shutil.copy(f, project_dir + '/' + metadata_dir + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK METADATA\n",
    "\n",
    "!echo CHECK METADATA\n",
    "!echo\n",
    "!echo {metadata_dir} :\n",
    "!echo\n",
    "!ls -1 {metadata_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MERGE METADATA\n",
    "\n",
    "## Delete old merged metadata\n",
    "print(metadata_dir, ': \\n')\n",
    "\n",
    "!rm -f {metadata_file}\n",
    "\n",
    "with open(metadata_file, 'w') as fout:\n",
    "    # copy header from first file\n",
    "    headerfile = open(metadata_csv_files[0])\n",
    "    fout.write(headerfile.readline())\n",
    "    ## copy bodies\n",
    "    wout = csv.writer(fout)\n",
    "    for filename in metadata_csv_files:\n",
    "        print('Processing', filename)\n",
    "        with open(filename, 'r') as fin:\n",
    "            win = csv.reader(fin)\n",
    "            next(win) # skip header\n",
    "            wout.writerows(win)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK MERGE\n",
    "\n",
    "!echo CHECK MERGE\n",
    "!echo\n",
    "!echo {metadata_file} :\n",
    "!echo\n",
    "!head -n 2 {metadata_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COPY TEXT\n",
    "## Replaced by the metadata csv export\n",
    "# for file in glob.glob(text_file_directory+r'/*.txt'):\n",
    "#    shutil.copy(file, project_directory+'/text_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPORT ARTICLE BODIES TO TEXT FILES\n",
    "\n",
    "## Source CSV fields:\n",
    "## id, publication, pubdate, title, articlebody, author, docUrl, wordcount\n",
    "\n",
    "## Delete old text files\n",
    "!rm -fr {text_files_dir}\n",
    "!mkdir -p {text_files_dir}\n",
    "\n",
    "## Export\n",
    "with open(metadata_file, 'r') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    ## skip header row\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        with open(project_dir+'/' + text_files_dir + '/'+ row['id'] + '_.txt', 'w') as outfile:\n",
    "            # writer = csv.DictWriter(outfile, fieldnames=outfieldnames)\n",
    "            outfile.write(row['articlebody'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CHECK TEXT FILES\n",
    "\n",
    "!echo CHECK TEXT FILES\n",
    "!echo\n",
    "!echo {text_files_dir} :\n",
    "!echo\n",
    "!ls -1 {text_files_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEXT\n",
    "## Generate a link to the next notebook in the workflow\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "browser_link_html = HTML('<p>The data is imported into ~/metadata/ and ~/text_files/.</p><h2><a href=\"2_clean_data.ipynb\" target=\"_blank\">Next: Clean Data.</h2>')\n",
    "display(browser_link_html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
